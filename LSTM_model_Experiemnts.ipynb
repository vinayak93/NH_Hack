{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\veena\\Documents\\NH Hackthon\\News _dataset\n"
     ]
    }
   ],
   "source": [
    "%cd \"C:\\Users\\veena\\Documents\\NH Hackthon\\News _dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fake_data = pd.read_csv(\"Fake.csv\")\n",
    "True_data = pd.read_csv(\"True.csv\")\n",
    "Fake_data[\"category_numeric\"] = 1\n",
    "True_data[\"category_numeric\"] = 0\n",
    "\n",
    "full_data = pd.concat([Fake_data,True_data], axis =0)\n",
    "\n",
    "X = full_data[[ 'text']]\n",
    "y = full_data['category_numeric']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35918, 1)\n",
      "(35918, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>13585</td>\n",
       "      <td>DUBLIN (Reuters) - Progress is being made in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8529</td>\n",
       "      <td>WASHINGTON (Reuters) - Republican presidential...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11314</td>\n",
       "      <td>PARIS (Reuters) - President Emmanuel Macron ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3128</td>\n",
       "      <td>(Reuters) - Democratic lawmakers investigating...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7810</td>\n",
       "      <td>WINSTON-SALEM, N.C. (Reuters) - A state judge ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6621</td>\n",
       "      <td>(Reuters) - The U.S. government spent more tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7406</td>\n",
       "      <td>LOS ANGELES (Reuters) - California voters turn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>728</td>\n",
       "      <td>BEIJING (Reuters) - U.S. President Donald Trum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16734</td>\n",
       "      <td>This is Barack Obama s Justice Department and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1745</td>\n",
       "      <td>Remember that explosive Russian dossier from a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35918 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "13585  DUBLIN (Reuters) - Progress is being made in t...\n",
       "8529   WASHINGTON (Reuters) - Republican presidential...\n",
       "11314  PARIS (Reuters) - President Emmanuel Macron ha...\n",
       "3128   (Reuters) - Democratic lawmakers investigating...\n",
       "7810   WINSTON-SALEM, N.C. (Reuters) - A state judge ...\n",
       "...                                                  ...\n",
       "6621   (Reuters) - The U.S. government spent more tha...\n",
       "7406   LOS ANGELES (Reuters) - California voters turn...\n",
       "728    BEIJING (Reuters) - U.S. President Donald Trum...\n",
       "16734  This is Barack Obama s Justice Department and ...\n",
       "1745   Remember that explosive Russian dossier from a...\n",
       "\n",
       "[35918 rows x 1 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8980, 1)\n",
      "(8980, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "maximum_words = 2000\n",
    "maximum_len = 190\n",
    "tokenize__ = Tokenizer(num_words=maximum_words)\n",
    "tokenize__.fit_on_texts(X_train.text)\n",
    "sequences = tok.texts_to_sequences(X_train.text)\n",
    "sequences_matrix = sequence.pad_sequences(sequences,maxlen=maximum_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 190)               0         \n",
      "_________________________________________________________________\n",
      "embedding_6 (Embedding)      (None, 190, 50)           100000    \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 64)                29440     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 2)                 514       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 146,594\n",
      "Trainable params: 146,594\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\veena\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28734 samples, validate on 7184 samples\n",
      "Epoch 1/5\n",
      "28734/28734 [==============================] - 49s 2ms/step - loss: 0.1326 - accuracy: 0.9490 - val_loss: 0.0776 - val_accuracy: 0.9772\n",
      "Epoch 2/5\n",
      "28734/28734 [==============================] - 51s 2ms/step - loss: 0.0621 - accuracy: 0.9811 - val_loss: 0.0711 - val_accuracy: 0.9830\n",
      "Epoch 3/5\n",
      "28734/28734 [==============================] - 51s 2ms/step - loss: 0.0464 - accuracy: 0.9865 - val_loss: 0.0515 - val_accuracy: 0.9875\n",
      "Epoch 4/5\n",
      "28734/28734 [==============================] - 51s 2ms/step - loss: 0.0329 - accuracy: 0.9900 - val_loss: 0.0551 - val_accuracy: 0.9865\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1c6b4a1fb88>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "%matplotlib inline\n",
    "\n",
    "def LSTMKerasModel_Dense2():\n",
    "    inputs = Input(name='inputs',shape=[maximum_len])\n",
    "    addlayer = Embedding(maximum_words,60,input_length=maximum_len)(inputs)\n",
    "    addlayer = LSTM(64)(addlayer)\n",
    "    addlayer = Dense(256,name='FC1')(addlayer)\n",
    "    addlayer = Activation('relu')(addlayer)\n",
    "    addlayer = Dropout(0.5)(addlayer)\n",
    "    addlayer = Dense(2,name='out_layer')(addlayer)\n",
    "    addlayer = Activation('softmax')(addlayer)\n",
    "    model = Model(inputs=inputs,outputs=addlayer)\n",
    "    return model\n",
    "\n",
    "model_1 = LSTMKerasModel_Dense2()\n",
    "model_1.summary()\n",
    "model_1.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.00005),metrics=['accuracy'])\n",
    "\n",
    "model_1.fit(sequences_matrix,Y_train,batch_size=128,epochs=5,\n",
    "          validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8980/8980 [==============================] - 7s 734us/step\n",
      "Test set\n",
      "  Loss: 0.065\n",
      "  Accuracy: 0.980\n"
     ]
    }
   ],
   "source": [
    "test_sequences = tok.texts_to_sequences(X_test.text)\n",
    "test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)\n",
    "\n",
    "#Y_test_cat = to_categorical(Y_test)\n",
    "accr = model_1.evaluate(test_sequences_matrix,Y_test)\n",
    "\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred =  model_1.predict(test_sequences_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.32      0.40      4293\n",
      "           1       0.54      0.73      0.62      4687\n",
      "\n",
      "   micro avg       0.54      0.54      0.54      8980\n",
      "   macro avg       0.53      0.53      0.51      8980\n",
      "weighted avg       0.53      0.54      0.52      8980\n",
      " samples avg       0.54      0.54      0.54      8980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, f1_score\n",
    "print(classification_report(Y_test , y_pred.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multilabel-indicator is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-5f1c10e04fa6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mcm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#plot_confusion_matrix(model, test_sequences_matrix, Y_test)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    268\u001b[0m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 270\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not supported\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    271\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: multilabel-indicator is not supported"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sn\n",
    "cm = confusion_matrix(Y_test, y_pred.round())\n",
    "\n",
    "#plot_confusion_matrix(model, test_sequences_matrix, Y_test)  \n",
    "#plt.show() \n",
    "\n",
    "sn.set(font_scale=1.4) # for label size\n",
    "sn.heatmap(cm, annot=True, annot_kws={\"size\": 12}) # font size\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.1569805e-01, 7.8430194e-01],\n",
       "       [4.4822478e-01, 5.5177522e-01],\n",
       "       [9.9992192e-01, 7.8081619e-05],\n",
       "       ...,\n",
       "       [9.9983799e-01, 1.6197674e-04],\n",
       "       [9.5277399e-01, 4.7225978e-02],\n",
       "       [2.7385462e-07, 9.9999976e-01]], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Jeanne Shaheen is the current senetor of New h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Joe Biden died in 48 seconds due to major hear...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Jeanne Shaheen is the current senetor of New h...\n",
       "1  Joe Biden died in 48 seconds due to major hear..."
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "Y_test\n",
    "dem = [0, 1]\n",
    "\n",
    "dem_cat_Y = to_categorical(dem)\n",
    "\n",
    "text = [\"Jeanne Shaheen is the current senetor of New hampshire\", \"Joe Biden died in 48 seconds due to major heart attack\"]\n",
    "dem_X = pd.DataFrame(data = text)\n",
    "dem_X.columns = ['text']\n",
    "dem_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 8ms/step\n",
      "Test set\n",
      "  Loss: 2.972\n",
      "  Accuracy: 0.500\n"
     ]
    }
   ],
   "source": [
    "\n",
    "demo_seq = tok.texts_to_sequences(dem_X.text)\n",
    "demo_seq_matrix = sequence.pad_sequences(demo_seq,maxlen=max_len)\n",
    "\n",
    "demo_acc = model_1.evaluate(demo_seq_matrix,dem_cat_Y)\n",
    "\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(demo_acc[0],demo_acc[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "2/2 [==============================] - 0s 33ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00263179, 0.9973683 ],\n",
       "       [0.0029583 , 0.99704164]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " model_1.predict(demo_seq_matrix,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\veena\\Documents\\NH Hackthon\n"
     ]
    }
   ],
   "source": [
    "%cd \"C:\\Users\\veena\\Documents\\NH Hackthon\"\n",
    "current_affair = pd.read_csv(\"current_affairs_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_train_data = current_affair[['Statement', 'category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Says there was a â€œ28% increase in children to ...\n",
       "1       \"Since 2006 Texas has given $19B in taxpayer s...\n",
       "2       â€œYou canâ€™t tell me they can (develop a safe va...\n",
       "3       We are sending back the vast majority of the f...\n",
       "4         Bull sharks were released in an Arkansas river.\n",
       "                              ...                        \n",
       "3946    Says U.S. Rep. John Carter \"hasnâ€™t held a town...\n",
       "3947    Says heâ€™s a \"small-town supervisor who has kep...\n",
       "3948    \"If you are a gun store owner and you decide t...\n",
       "3949    \"Half of everyone thatâ€™s here illegally (in th...\n",
       "3950    \"Thanks to President Trump and Republican lead...\n",
       "Name: Statement, Length: 3951, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_train_data.Statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\veena\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "current_train_data['category_numeric'] = [0 if x =='TRUE' else 1 for x in current_train_data['category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Statement</th>\n",
       "      <th>category</th>\n",
       "      <th>category_numeric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Says there was a â€œ28% increase in children to ...</td>\n",
       "      <td>fake</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>\"Since 2006 Texas has given $19B in taxpayer s...</td>\n",
       "      <td>fake</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>â€œYou canâ€™t tell me they can (develop a safe va...</td>\n",
       "      <td>fake</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>We are sending back the vast majority of the f...</td>\n",
       "      <td>fake</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Bull sharks were released in an Arkansas river.</td>\n",
       "      <td>fake</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3946</td>\n",
       "      <td>Says U.S. Rep. John Carter \"hasnâ€™t held a town...</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3947</td>\n",
       "      <td>Says heâ€™s a \"small-town supervisor who has kep...</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3948</td>\n",
       "      <td>\"If you are a gun store owner and you decide t...</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3949</td>\n",
       "      <td>\"Half of everyone thatâ€™s here illegally (in th...</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3950</td>\n",
       "      <td>\"Thanks to President Trump and Republican lead...</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3951 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Statement category  \\\n",
       "0     Says there was a â€œ28% increase in children to ...     fake   \n",
       "1     \"Since 2006 Texas has given $19B in taxpayer s...     fake   \n",
       "2     â€œYou canâ€™t tell me they can (develop a safe va...     fake   \n",
       "3     We are sending back the vast majority of the f...     fake   \n",
       "4       Bull sharks were released in an Arkansas river.     fake   \n",
       "...                                                 ...      ...   \n",
       "3946  Says U.S. Rep. John Carter \"hasnâ€™t held a town...     TRUE   \n",
       "3947  Says heâ€™s a \"small-town supervisor who has kep...     TRUE   \n",
       "3948  \"If you are a gun store owner and you decide t...     TRUE   \n",
       "3949  \"Half of everyone thatâ€™s here illegally (in th...     TRUE   \n",
       "3950  \"Thanks to President Trump and Republican lead...     TRUE   \n",
       "\n",
       "      category_numeric  \n",
       "0                    1  \n",
       "1                    1  \n",
       "2                    1  \n",
       "3                    1  \n",
       "4                    1  \n",
       "...                ...  \n",
       "3946                 0  \n",
       "3947                 0  \n",
       "3948                 0  \n",
       "3949                 0  \n",
       "3950                 0  \n",
       "\n",
       "[3951 rows x 3 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_affair_X = current_train_data[['Statement']]\n",
    "current_affair_Y = current_train_data.category_numeric\n",
    "\n",
    "current_affair_Y = to_categorical(current_affair_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok.fit_on_texts(current_affair_X.Statement)\n",
    "current_affair_sequences = tok.texts_to_sequences(current_affair_X.Statement)\n",
    "current_affair_sequences_matrix = sequence.pad_sequences(current_affair_sequences,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3951/3951 [==============================] - 15s 4ms/step - loss: 0.1424 - accuracy: 0.9438\n",
      "Epoch 2/10\n",
      "3951/3951 [==============================] - 15s 4ms/step - loss: 0.1110 - accuracy: 0.9577\n",
      "Epoch 3/10\n",
      "3951/3951 [==============================] - 14s 4ms/step - loss: 0.0785 - accuracy: 0.9747\n",
      "Epoch 4/10\n",
      "3951/3951 [==============================] - 14s 4ms/step - loss: 0.0525 - accuracy: 0.9823\n",
      "Epoch 5/10\n",
      "3951/3951 [==============================] - 14s 4ms/step - loss: 0.0477 - accuracy: 0.9828\n",
      "Epoch 6/10\n",
      "3951/3951 [==============================] - 14s 4ms/step - loss: 0.0345 - accuracy: 0.9884\n",
      "Epoch 7/10\n",
      "3951/3951 [==============================] - 14s 4ms/step - loss: 0.0168 - accuracy: 0.9937\n",
      "Epoch 8/10\n",
      "3951/3951 [==============================] - 15s 4ms/step - loss: 0.0111 - accuracy: 0.9954\n",
      "Epoch 9/10\n",
      "3951/3951 [==============================] - 14s 4ms/step - loss: 0.0229 - accuracy: 0.9932\n",
      "Epoch 10/10\n",
      "3951/3951 [==============================] - 15s 4ms/step - loss: 0.0241 - accuracy: 0.9939\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1c6cdefc2c8>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.fit(current_affair_sequences_matrix,current_affair_Y,batch_size=128,epochs=10,\n",
    "          validation_split=0,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_affair_set2 = pd.read_csv(\"current_affairs_new_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_affair_set2_data = current_affair_set2[['Statement', 'category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_affair_set2_X = current_affair_set2_data[['Statement']]\n",
    "current_affair_set2_Y = current_affair_set2_data.category\n",
    "\n",
    "current_affair_set2_Y = to_categorical(current_affair_set2_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok.fit_on_texts(current_affair_set2_X.Statement)\n",
    "current_affair_sequences_set2 = tok.texts_to_sequences(current_affair_set2_X.Statement)\n",
    "current_affair_sequences_matrix_set2 = sequence.pad_sequences(current_affair_sequences_set2,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "15633/15633 [==============================] - 60s 4ms/step - loss: 0.2600 - accuracy: 0.8774\n",
      "Epoch 2/20\n",
      "15633/15633 [==============================] - 58s 4ms/step - loss: 0.2205 - accuracy: 0.8960\n",
      "Epoch 3/20\n",
      "15633/15633 [==============================] - 59s 4ms/step - loss: 0.1770 - accuracy: 0.9219\n",
      "Epoch 4/20\n",
      "15633/15633 [==============================] - 60s 4ms/step - loss: 0.1560 - accuracy: 0.9336\n",
      "Epoch 5/20\n",
      "15633/15633 [==============================] - 54s 3ms/step - loss: 0.1293 - accuracy: 0.9459\n",
      "Epoch 6/20\n",
      "15633/15633 [==============================] - 54s 3ms/step - loss: 0.0975 - accuracy: 0.9618\n",
      "Epoch 7/20\n",
      "15633/15633 [==============================] - 56s 4ms/step - loss: 0.0768 - accuracy: 0.9713\n",
      "Epoch 8/20\n",
      "15633/15633 [==============================] - 54s 3ms/step - loss: 0.0698 - accuracy: 0.9732\n",
      "Epoch 9/20\n",
      "15633/15633 [==============================] - 56s 4ms/step - loss: 0.0725 - accuracy: 0.9750\n",
      "Epoch 10/20\n",
      "15633/15633 [==============================] - 61s 4ms/step - loss: 0.0592 - accuracy: 0.9784\n",
      "Epoch 11/20\n",
      "15633/15633 [==============================] - 62s 4ms/step - loss: 0.0425 - accuracy: 0.9868\n",
      "Epoch 12/20\n",
      "15633/15633 [==============================] - 57s 4ms/step - loss: 0.0366 - accuracy: 0.9878\n",
      "Epoch 13/20\n",
      "15633/15633 [==============================] - 59s 4ms/step - loss: 0.0393 - accuracy: 0.9877\n",
      "Epoch 14/20\n",
      "15633/15633 [==============================] - 59s 4ms/step - loss: 0.0292 - accuracy: 0.9904\n",
      "Epoch 15/20\n",
      "15633/15633 [==============================] - 59s 4ms/step - loss: 0.0382 - accuracy: 0.9871\n",
      "Epoch 16/20\n",
      "15633/15633 [==============================] - 61s 4ms/step - loss: 0.0273 - accuracy: 0.9910\n",
      "Epoch 17/20\n",
      "15633/15633 [==============================] - 62s 4ms/step - loss: 0.0600 - accuracy: 0.9800\n",
      "Epoch 18/20\n",
      "15633/15633 [==============================] - 62s 4ms/step - loss: 0.0298 - accuracy: 0.9915\n",
      "Epoch 19/20\n",
      "15633/15633 [==============================] - 62s 4ms/step - loss: 0.0225 - accuracy: 0.9928\n",
      "Epoch 20/20\n",
      "15633/15633 [==============================] - 62s 4ms/step - loss: 0.0165 - accuracy: 0.9950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1c6b5790108>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.fit(current_affair_sequences_matrix_set2,current_affair_set2_Y,batch_size=128,epochs=20,\n",
    "          validation_split=0,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model_1.to_json()\n",
    "with open(\"model_1_LSTM_Dense2.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model_1.save_weights(\"model_1_LSTM_Dense2.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
