{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\veena\\Documents\\NH Hackthon\\News _dataset\n"
     ]
    }
   ],
   "source": [
    "%cd \"C:\\Users\\veena\\Documents\\NH Hackthon\\News _dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fake_data = pd.read_csv(\"Fake.csv\")\n",
    "True_data = pd.read_csv(\"True.csv\")\n",
    "Fake_data[\"category_numeric\"] = 1\n",
    "True_data[\"category_numeric\"] = 0\n",
    "\n",
    "full_data = pd.concat([Fake_data,True_data], axis =0)\n",
    "\n",
    "X = full_data[[ 'text']]\n",
    "y = full_data['category_numeric']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "#one hot encoding\n",
    "\n",
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(y)\n",
    "Y = Y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "max_words = 1000\n",
    "max_len = 150\n",
    "tok = Tokenizer(num_words=max_words)\n",
    "tok.fit_on_texts(X_train.text)\n",
    "sequences = tok.texts_to_sequences(X_train.text)\n",
    "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "embedding_8 (Embedding)      (None, 150, 50)           50000     \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 64)                29440     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 96,337\n",
      "Trainable params: 96,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\veena\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28734 samples, validate on 7184 samples\n",
      "Epoch 1/10\n",
      "28734/28734 [==============================] - 68s 2ms/step - loss: 0.6648 - accuracy: 0.7821 - val_loss: 0.5061 - val_accuracy: 0.7741\n",
      "Epoch 2/10\n",
      "28734/28734 [==============================] - 68s 2ms/step - loss: 0.2874 - accuracy: 0.8934 - val_loss: 0.1673 - val_accuracy: 0.9472\n",
      "Epoch 3/10\n",
      "28734/28734 [==============================] - 68s 2ms/step - loss: 0.1343 - accuracy: 0.9590 - val_loss: 0.1174 - val_accuracy: 0.9653\n",
      "Epoch 4/10\n",
      "28734/28734 [==============================] - 68s 2ms/step - loss: 0.0984 - accuracy: 0.9706 - val_loss: 0.0953 - val_accuracy: 0.9720\n",
      "Epoch 5/10\n",
      "28734/28734 [==============================] - 68s 2ms/step - loss: 0.0794 - accuracy: 0.9764 - val_loss: 0.0823 - val_accuracy: 0.9747\n",
      "Epoch 6/10\n",
      "28734/28734 [==============================] - 68s 2ms/step - loss: 0.0649 - accuracy: 0.9812 - val_loss: 0.0755 - val_accuracy: 0.9765\n",
      "Epoch 7/10\n",
      "28734/28734 [==============================] - 68s 2ms/step - loss: 0.0566 - accuracy: 0.9841 - val_loss: 0.0743 - val_accuracy: 0.9770\n",
      "Epoch 8/10\n",
      "28734/28734 [==============================] - 68s 2ms/step - loss: 0.0494 - accuracy: 0.9864 - val_loss: 0.0641 - val_accuracy: 0.9798\n",
      "Epoch 9/10\n",
      "28734/28734 [==============================] - 68s 2ms/step - loss: 0.0452 - accuracy: 0.9874 - val_loss: 0.0624 - val_accuracy: 0.9801\n",
      "Epoch 10/10\n",
      "28734/28734 [==============================] - 68s 2ms/step - loss: 0.0406 - accuracy: 0.9886 - val_loss: 0.0569 - val_accuracy: 0.9822\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a1476088c8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "%matplotlib inline\n",
    "\n",
    "def LSTMKerasModel():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
    "    layer = LSTM(64)(layer)\n",
    "    layer = Dense(256,name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.5)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model\n",
    "\n",
    "\n",
    "model = LSTMKerasModel()\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.00005),metrics=['accuracy'])\n",
    "\n",
    "model.fit(sequences_matrix,Y_train,batch_size=128,epochs=10,\n",
    "          validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8980/8980 [==============================] - 7s 786us/step\n",
      "Test set\n",
      "  Loss: 0.048\n",
      "  Accuracy: 0.984\n"
     ]
    }
   ],
   "source": [
    "test_seq = tokenize__.texts_to_sequences(X_test.text)\n",
    "test_seq_matrix = sequence.pad_sequences(test_seq,maxlen=max_len)\n",
    "\n",
    "accr = model.evaluate(test_seq_matrix,Y_test)\n",
    "\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred =  model.predict(test_seq_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      4316\n",
      "           1       0.99      0.98      0.98      4664\n",
      "\n",
      "    accuracy                           0.98      8980\n",
      "   macro avg       0.98      0.98      0.98      8980\n",
      "weighted avg       0.98      0.98      0.98      8980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, f1_score\n",
    "print(classification_report(Y_test , y_pred.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sn\n",
    "cm = confusion_matrix(Y_test, y_pred.round())\n",
    "\n",
    "#plot_confusion_matrix(model, test_sequences_matrix, Y_test)  \n",
    "#plt.show() \n",
    "\n",
    "#sn.set(font_scale=1.4) # for label size\n",
    "sn.heatmap(cm, annot=True, annot_kws={\"size\": 16}) # font size\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\veena\\Documents\\NH Hackthon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\veena\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3951/3951 [==============================] - 8s 2ms/step - loss: 0.5364 - accuracy: 0.7970\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\veena\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3951/3951 [==============================] - 8s 2ms/step - loss: 0.4927 - accuracy: 0.8087\n",
      "Epoch 3/20\n",
      "3951/3951 [==============================] - 9s 2ms/step - loss: 0.4724 - accuracy: 0.8127\n",
      "Epoch 4/20\n",
      "3951/3951 [==============================] - 9s 2ms/step - loss: 0.4600 - accuracy: 0.8152\n",
      "Epoch 5/20\n",
      "3951/3951 [==============================] - 9s 2ms/step - loss: 0.4538 - accuracy: 0.8175\n",
      "Epoch 6/20\n",
      "3951/3951 [==============================] - 9s 2ms/step - loss: 0.4475 - accuracy: 0.8185\n",
      "Epoch 7/20\n",
      "3951/3951 [==============================] - 9s 2ms/step - loss: 0.4428 - accuracy: 0.8213\n",
      "Epoch 8/20\n",
      "3951/3951 [==============================] - 9s 2ms/step - loss: 0.4370 - accuracy: 0.8231\n",
      "Epoch 9/20\n",
      "3951/3951 [==============================] - 9s 2ms/step - loss: 0.4329 - accuracy: 0.8246\n",
      "Epoch 10/20\n",
      "3951/3951 [==============================] - 9s 2ms/step - loss: 0.4300 - accuracy: 0.8254\n",
      "Epoch 11/20\n",
      "3951/3951 [==============================] - 9s 2ms/step - loss: 0.4248 - accuracy: 0.8281\n",
      "Epoch 12/20\n",
      "3951/3951 [==============================] - 9s 2ms/step - loss: 0.4202 - accuracy: 0.8299\n",
      "Epoch 13/20\n",
      "3951/3951 [==============================] - 9s 2ms/step - loss: 0.4168 - accuracy: 0.8317\n",
      "Epoch 14/20\n",
      "3951/3951 [==============================] - 9s 2ms/step - loss: 0.4141 - accuracy: 0.8327\n",
      "Epoch 15/20\n",
      "3951/3951 [==============================] - 9s 2ms/step - loss: 0.4092 - accuracy: 0.8337\n",
      "Epoch 16/20\n",
      "3951/3951 [==============================] - 9s 2ms/step - loss: 0.4065 - accuracy: 0.8319\n",
      "Epoch 17/20\n",
      "3951/3951 [==============================] - 9s 2ms/step - loss: 0.4031 - accuracy: 0.8370\n",
      "Epoch 18/20\n",
      "3951/3951 [==============================] - 9s 2ms/step - loss: 0.4011 - accuracy: 0.8380\n",
      "Epoch 19/20\n",
      "3951/3951 [==============================] - 9s 2ms/step - loss: 0.3941 - accuracy: 0.8393\n",
      "Epoch 20/20\n",
      "3951/3951 [==============================] - 9s 2ms/step - loss: 0.3921 - accuracy: 0.8423\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a1395af3c8>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd \"C:\\Users\\veena\\Documents\\NH Hackthon\"\n",
    "current_affair = pd.read_csv(\"current_affairs_new.csv\")\n",
    "\n",
    "current_train_data = current_affair[['Statement', 'category']]\n",
    "current_train_data['category_numeric'] = [0 if x =='TRUE' else 1 for x in current_train_data['category']]\n",
    "\n",
    "current_affair_X = current_train_data[['Statement']]\n",
    "current_affair_Y = current_train_data.category_numeric\n",
    "\n",
    "current_affair_Y = le.fit_transform(current_affair_Y)\n",
    "current_affair_Y = current_affair_Y.reshape(-1,1)\n",
    "#current_affair_Y = to_categorical(current_affair_Y)\n",
    "\n",
    "tokenize__.fit_on_texts(current_affair_X.Statement)\n",
    "current_affair_sequences = tokenize__.texts_to_sequences(current_affair_X.Statement)\n",
    "current_affair_sequences_matrix = sequence.pad_sequences(current_affair_sequences,maxlen=max_len)\n",
    "\n",
    "model.fit(current_affair_sequences_matrix,current_affair_Y,batch_size=128,epochs=20,\n",
    "          validation_split=0,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "15633/15633 [==============================] - 33s 2ms/step - loss: 0.6697 - accuracy: 0.6294\n",
      "Epoch 2/25\n",
      "15633/15633 [==============================] - 35s 2ms/step - loss: 0.6326 - accuracy: 0.6492\n",
      "Epoch 3/25\n",
      "15633/15633 [==============================] - 36s 2ms/step - loss: 0.6196 - accuracy: 0.6599\n",
      "Epoch 4/25\n",
      "15633/15633 [==============================] - 36s 2ms/step - loss: 0.6116 - accuracy: 0.6674\n",
      "Epoch 5/25\n",
      "15633/15633 [==============================] - 37s 2ms/step - loss: 0.6047 - accuracy: 0.6737\n",
      "Epoch 6/25\n",
      "15633/15633 [==============================] - 37s 2ms/step - loss: 0.6001 - accuracy: 0.6781\n",
      "Epoch 7/25\n",
      "15633/15633 [==============================] - 37s 2ms/step - loss: 0.5947 - accuracy: 0.6829\n",
      "Epoch 8/25\n",
      "15633/15633 [==============================] - 36s 2ms/step - loss: 0.5909 - accuracy: 0.6873\n",
      "Epoch 9/25\n",
      "15633/15633 [==============================] - 36s 2ms/step - loss: 0.5868 - accuracy: 0.6914\n",
      "Epoch 10/25\n",
      "15633/15633 [==============================] - 36s 2ms/step - loss: 0.5836 - accuracy: 0.6963\n",
      "Epoch 11/25\n",
      "15633/15633 [==============================] - 36s 2ms/step - loss: 0.5806 - accuracy: 0.6987\n",
      "Epoch 12/25\n",
      "15633/15633 [==============================] - 36s 2ms/step - loss: 0.5777 - accuracy: 0.7001\n",
      "Epoch 13/25\n",
      "15633/15633 [==============================] - 37s 2ms/step - loss: 0.5744 - accuracy: 0.7049\n",
      "Epoch 14/25\n",
      "15633/15633 [==============================] - 37s 2ms/step - loss: 0.5717 - accuracy: 0.7061\n",
      "Epoch 15/25\n",
      "15633/15633 [==============================] - 36s 2ms/step - loss: 0.5698 - accuracy: 0.7077\n",
      "Epoch 16/25\n",
      "15633/15633 [==============================] - 36s 2ms/step - loss: 0.5674 - accuracy: 0.7109\n",
      "Epoch 17/25\n",
      "15633/15633 [==============================] - 36s 2ms/step - loss: 0.5648 - accuracy: 0.7122\n",
      "Epoch 18/25\n",
      "15633/15633 [==============================] - 36s 2ms/step - loss: 0.5628 - accuracy: 0.7131\n",
      "Epoch 19/25\n",
      "15633/15633 [==============================] - 36s 2ms/step - loss: 0.5606 - accuracy: 0.7155\n",
      "Epoch 20/25\n",
      "15633/15633 [==============================] - 36s 2ms/step - loss: 0.5593 - accuracy: 0.7168\n",
      "Epoch 21/25\n",
      "15633/15633 [==============================] - 36s 2ms/step - loss: 0.5576 - accuracy: 0.7178\n",
      "Epoch 22/25\n",
      "15633/15633 [==============================] - 36s 2ms/step - loss: 0.5556 - accuracy: 0.7182\n",
      "Epoch 23/25\n",
      "15633/15633 [==============================] - 36s 2ms/step - loss: 0.5547 - accuracy: 0.7200\n",
      "Epoch 24/25\n",
      "15633/15633 [==============================] - 36s 2ms/step - loss: 0.5532 - accuracy: 0.7208\n",
      "Epoch 25/25\n",
      "15633/15633 [==============================] - 36s 2ms/step - loss: 0.5521 - accuracy: 0.7226\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a13aa13cc8>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_affair_set2 = pd.read_csv(\"current_affairs_new_2.csv\")\n",
    "current_affair_set2_data = current_affair_set2[['Statement', 'category']]\n",
    "\n",
    "current_affair_set2_X = current_affair_set2_data[['Statement']]\n",
    "current_affair_set2_Y = current_affair_set2_data.category\n",
    "\n",
    "\n",
    "current_affair_set2_Y = le.fit_transform(current_affair_set2_Y)\n",
    "current_affair_set2_Y = current_affair_set2_Y.reshape(-1,1)\n",
    "\n",
    "tokenize__.fit_on_texts(current_affair_set2_X.Statement)\n",
    "current_affair_sequences_set2 = tokenize__.texts_to_sequences(current_affair_set2_X.Statement)\n",
    "current_affair_sequences_matrix_set2 = sequence.pad_sequences(current_affair_sequences_set2,maxlen=maximum_len)\n",
    "\n",
    "model.fit(current_affair_sequences_matrix_set2,current_affair_set2_Y,batch_size=128,epochs=25,\n",
    "          validation_split=0,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model_LSTM_Dense_layer_1.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model_LSTM_Dense_layer_1.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "external_stylesheets = ['https://codepen.io/chriddyp/pen/bWLwgP.css']\n",
    "\n",
    "app = dash.Dash(__name__, external_stylesheets=external_stylesheets)\n",
    "\n",
    "# assume you have a \"long-form\" data frame\n",
    "# see https://plotly.com/python/px-arguments/ for more options\n",
    "df = pd.DataFrame({\n",
    "    \"Fruit\": [\"Apples\", \"Oranges\", \"Bananas\", \"Apples\", \"Oranges\", \"Bananas\"],\n",
    "    \"Amount\": [4, 1, 2, 2, 4, 5],\n",
    "    \"City\": [\"SF\", \"SF\", \"SF\", \"Montreal\", \"Montreal\", \"Montreal\"]\n",
    "})\n",
    "\n",
    "fig = px.bar(df, x=\"Fruit\", y=\"Amount\", color=\"City\", barmode=\"group\")\n",
    "\n",
    "app.layout = html.Div(children=[\n",
    "    html.H1(children='Hello Dash'),\n",
    "\n",
    "    html.Div(children='''\n",
    "        Dash: A web application framework for Python.\n",
    "    '''),\n",
    "\n",
    "    dcc.Graph(\n",
    "        id='example-graph',\n",
    "        figure=fig\n",
    "    ),\n",
    "    \n",
    "    dcc.Textarea(\n",
    "    placeholder='Enter a value...',\n",
    "    value='This is a TextArea component',\n",
    "    style={'width': '100%'}\n",
    ")  \n",
    "])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
